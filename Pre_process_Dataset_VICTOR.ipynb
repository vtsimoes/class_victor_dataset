{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD0/vdMU7WfOLO4KEuNSNq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vtsimoes/class_victor_dataset/blob/main/G_Pre_process_VICTOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pré-processamento dos dados do DATASET VICTOR\n"
      ],
      "metadata": {
        "id": "qJv3Q54tCM8V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVvOv0Xq_YQK"
      },
      "outputs": [],
      "source": [
        "#Load required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('rslp')\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pylab\n",
        "import time\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções para salvar os dados pré-processados"
      ],
      "metadata": {
        "id": "dHMuRRJZGvDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pickle(data_to_save,path='',filename='file.pkl'):\n",
        "  open_file = open(path + filename, \"wb\")\n",
        "  pickle.dump(data_to_save, open_file)\n",
        "  open_file.close()\n",
        "\n",
        "def load_pickle(path='',filename='file.pkl'):\n",
        "  open_file = open(path + filename, \"rb\")\n",
        "  pkl_file = pickle.load(open_file)\n",
        "  open_file.close()\n",
        "  return pkl_file"
      ],
      "metadata": {
        "id": "FQexe0JLGvb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#definição dos paths com os Dados do dataset\n",
        "path = ''\n",
        "path_dados = ''\n",
        "path_preprocessados = ''\n",
        "#Montando o google drive para obter os dados\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "LYhCRv6oG4JH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6bb831-8a11-49e4-91ac-26b51a64765e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento do DATASET VICTOR"
      ],
      "metadata": {
        "id": "Lq034wWbG-IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename_test = \"test_small.csv\"\n",
        "filename_train = \"train_small.csv\"\n",
        "filename_validation = \"validation_small.csv\""
      ],
      "metadata": {
        "id": "ovKeRHVwG7h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(path+'small/'+filename_train)\n",
        "valid = pd.read_csv(path+'small/'+ filename_validation)\n",
        "test = pd.read_csv(path+'small/'+filename_test)"
      ],
      "metadata": {
        "id": "VuESOAwKHJyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando o carregamento dos dados e entendendo o formato"
      ],
      "metadata": {
        "id": "sUXpG-CbH7Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test.loc[test.body.str.contains('LEI_')]"
      ],
      "metadata": {
        "id": "xtIYPP2CL14n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.loc[(test.file_name == 'AI_859014_2811603_50_16052013.pdf') & (test.pages == 3)].body.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxn9TNRNMs5x",
        "outputId": "01524388-6e50-4165-eaa9-5c29d4e23857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['{\"colendo supremo tribunal federal senhores ministros razões recursais síntese decisão recorrida trata de decisão presidente turma recursal dos juizados especiais seção judiciária estado paraíba que negou seguimento recurso extraordinário união nos seguintes termos decisão cuida de recurso extraordinário interposto contra acórdão deste órgão colegiado que rejeitou alegação prescrição negou seguimento recurso ente público mantendo sentença recorrida por seus próprios fundamentos eis que calçada posicionamento reiterado supremo tribunal federal dispõe LEI_10259 que instituiu juizados especiais federais cíveis criminais âmbito justiça federal ARTIGO_14 caberá pedido uniformização interpretação lei federal quando houver divergência entre decisões sobre questões direito material proferidas por turmas recursais interpretação LEI_4º quando orientação acolhida pela turma uniformização questões direito material contrariar súmula jurisprudência dominante superior tribunal justiça stj parte interessada poderá provocar manifestação deste que dirimirá divergência caso presente plausibilidade direito invocado havendo fundado receio dano difícil reparação poderá relator\"}'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento para remoção de vazios, e tokens desnecessários"
      ],
      "metadata": {
        "id": "wtxfEGlXoJkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Removendo \"{}\" do campo de textos"
      ],
      "metadata": {
        "id": "iqhJPQI5oJkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_trash(df, column=\"body\"):\n",
        "    df[column] = df[column].str.strip('{}\"')\n",
        "    return df"
      ],
      "metadata": {
        "id": "J9I9364SoJkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clean = strip_trash(train)\n",
        "valid_clean = strip_trash(valid)\n",
        "test_clean = strip_trash(test)"
      ],
      "metadata": {
        "id": "JB9ErxfRoJko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(train)\n",
        "del(valid)\n",
        "del(test)"
      ],
      "metadata": {
        "id": "EIkVWQc8oJkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_md #Carregando o módulo de português do Brasil do Spacy"
      ],
      "metadata": {
        "id": "okrw_Nq4b1rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"pt_core_news_md\")"
      ],
      "metadata": {
        "id": "AV-a5dN9I1SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preProcessData(df,remove_stopwords=True,lemma = False):\n",
        "  docs = []\n",
        "  labels = []\n",
        "  file_name = []\n",
        "  pages = []\n",
        "  trunked = []\n",
        "  stops = ['fls.','fls','fl.','fl','pg.','pg']\n",
        "  if remove_stopwords:\n",
        "    stop_words = set(stopwords.words('portuguese'))\n",
        "    for stop in stops:\n",
        "      stop_words.add(stop)\n",
        "  else:\n",
        "    print('Sem remoção de stopwords')\n",
        "    stop_words = set(stops)\n",
        "  #padrão para remoção de links\n",
        "  for i, row in df.iterrows():\n",
        "    labels.append(row.document_type)\n",
        "    file_name.append(row.file_name)\n",
        "    pages.append(row.pages)\n",
        "    doc = re.sub(r\"http\\S+\", \"\", row.body) #remove links\n",
        "    doc = doc.lower()\n",
        "    if lemma:\n",
        "      lemmatize = nlp(doc)\n",
        "      tokens = []\n",
        "      for token in lemmatize:\n",
        "        tokens.append(token)\n",
        "      doc = ' '.join([token.lemma_ for token in tokens])\n",
        "\n",
        "    docs.append(doc)\n",
        "\n",
        "  se_doc = pd.Series(data=docs)\n",
        "  df_doc = pd.DataFrame(data=se_doc,columns=['body'])\n",
        "  df_doc['document_type'] = labels\n",
        "  df_doc['file_name'] = file_name\n",
        "  df_doc['pages'] = pages\n",
        "  df_doc['body'] = df_doc['body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "  return df_doc"
      ],
      "metadata": {
        "id": "mBhTnFGmoJkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_processed = preProcessData(train_clean,remove_stopwords=True, lemma= True)\n",
        "del(train_clean)\n",
        "df_test_processed = preProcessData(test_clean,remove_stopwords=True, lemma= True)\n",
        "del(test_clean)\n",
        "df_valid_processed = preProcessData(valid_clean,remove_stopwords=True, lemma= True)\n",
        "del(valid_clean)"
      ],
      "metadata": {
        "id": "y5cVPMw9oJks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para exibir as quantidade de documentos\n",
        "def quantidades(df):\n",
        "  print(df.document_type.value_counts(), df.document_type.value_counts()/len(df))"
      ],
      "metadata": {
        "id": "WxUcIl5doJku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Removendo dados vazios"
      ],
      "metadata": {
        "id": "WNz1UZKdoJkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_proc_sem_vazio =  df_train_processed.loc[df_train_processed.body.str.len() != 0]\n",
        "del(df_train_processed)\n",
        "df_test_proc_sem_vazio =  df_test_processed.loc[df_test_processed.body.str.len() != 0]\n",
        "del(df_test_processed)\n",
        "df_valid_proc_sem_vazio =  df_valid_processed.loc[df_valid_processed.body.str.len() != 0]\n",
        "del(df_valid_processed)"
      ],
      "metadata": {
        "id": "MFeYdLTNoJkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantidades(df_train_proc_sem_vazio)"
      ],
      "metadata": {
        "id": "CkeA8hwaoJkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantidades(df_test_proc_sem_vazio)"
      ],
      "metadata": {
        "id": "Yn9kk_wJoJkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantidades(df_valid_proc_sem_vazio)"
      ],
      "metadata": {
        "id": "W7niu6IkoJky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvando os dados pré-processados"
      ],
      "metadata": {
        "id": "gevRj4Q1X7K0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_pickle(df_train_proc_sem_vazio,path=path_dados+path_preprocessados,filename='train_processed_per_page_sw_lemma.pkl')\n",
        "save_pickle(df_valid_proc_sem_vazio,path=path_dados+path_preprocessados,filename='valid_processed_per_page_sw_lemma.pkl')\n",
        "save_pickle(df_test_proc_sem_vazio,path=path_dados+path_preprocessados,filename='test_processed_per_page_sw_lemma.pkl')"
      ],
      "metadata": {
        "id": "aN_2TMoXoJk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando os documentos pré-processados e sem as páginas unidas para teste de pré-processamento"
      ],
      "metadata": {
        "id": "7HVw610UeuIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = load_pickle(path=path_dados+path_preprocessados,filename='test_processed_per_page_sw_lemma.pkl')"
      ],
      "metadata": {
        "id": "rHa1kjOF0w0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.loc[(test.file_name == 'AI_859014_2811603_50_16052013.pdf') & (test.pages == 3)].body.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm5ku2sE1vdj",
        "outputId": "fd580221-1e88-49ba-b65a-490e0ee000c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['coler Supremo tribunal federal senhor ministro razão recursal síntese decisão recorrir tratar decisão presidente turma recursal juizado especial seção judiciário estado paraíba negar seguimento recurso extraordinário união seguinte termo decisão cuidar recurso extraordinário interposto contra acórdão órgão colegiado rejeitar alegação prescrição negar seguimento recurso ente público manter sentença recorrir próprio fundamento eis calçada posicionamento reiterar Supremo tribunal federal dispor LEI_10259 instituir juizado especial federal cível criminal âmbitor justiça federal ARTIGO_14 caber pedir uniformização interpretação lei federal divergência decisão sobre questão direito material proferir turma recursal interpretação LEI_4º orientação acolhir turma uniformização questão direito material contrariar súmula jurisprudência dominante alto tribunal Justiça stj parte interessado poder provocar manifestação dirimir divergência caso presente plausibilidade direito invocar fundar receio dano difícil reparação poder relator'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Texto Original\n",
        "\n",
        "\n",
        "\n",
        "\"colendo supremo tribunal federal senhores ministros razões recursais síntese decisão recorrida trata de decisão presidente turma recursal dos juizados especiais seção judiciária estado paraíba que negou seguimento recurso extraordinário união nos seguintes termos decisão cuida de recurso extraordinário interposto contra acórdão deste órgão colegiado que rejeitou alegação prescrição negou seguimento recurso ente público mantendo sentença recorrida por seus próprios fundamentos eis que calçada posicionamento reiterado supremo tribunal federal dispõe LEI_10259 que instituiu juizados especiais federais cíveis criminais âmbito justiça federal ARTIGO_14 caberá pedido uniformização interpretação lei federal quando houver divergência entre decisões sobre questões direito material proferidas por turmas recursais interpretação LEI_4º quando orientação acolhida pela turma uniformização questões direito material contrariar súmula jurisprudência dominante superior tribunal justiça stj parte interessada poderá provocar manifestação deste que dirimirá divergência caso presente plausibilidade direito invocado havendo fundado receio dano difícil reparação poderá relator\""
      ],
      "metadata": {
        "id": "bT62paZZ2I_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Texto Após pré-processamento\n",
        "\n",
        "'coler Supremo tribunal federal senhor ministro razão recursal síntese decisão recorrir tratar decisão presidente turma recursal juizado especial seção judiciário estado paraíba negar seguimento recurso extraordinário união seguinte termo decisão cuidar recurso extraordinário interposto contra acórdão órgão colegiado rejeitar alegação prescrição negar seguimento recurso ente público manter sentença recorrir próprio fundamento eis calçada posicionamento reiterar Supremo tribunal federal dispor LEI_10259 instituir juizado especial federal cível criminal âmbitor justiça federal ARTIGO_14 caber pedir uniformização interpretação lei federal divergência decisão sobre questão direito material proferir turma recursal interpretação LEI_4º orientação acolhir turma uniformização questão direito material contrariar súmula jurisprudência dominante alto tribunal Justiça stj parte interessado poder provocar manifestação dirimir divergência caso presente plausibilidade direito invocar fundar receio dano difícil reparação poder relator'\n",
        "\n"
      ],
      "metadata": {
        "id": "rv28Y5YR2h6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_proc_sem_vazio = load_pickle(path=path_dados+path_preprocessados,filename='train_processed_per_page.pkl')\n",
        "df_valid_proc_sem_vazio = load_pickle(path=path_dados+path_preprocessados,filename='valid_processed_per_page.pkl')\n",
        "df_test_proc_sem_vazio = load_pickle(path=path_dados+path_preprocessados,filename='test_processed_per_page.pkl')"
      ],
      "metadata": {
        "id": "niymvEZLettH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Juntando as páginas em um único documento\n",
        "\n",
        "Lembrando que o Dataset VICTOR separa os documentos por página em cada linha do dataframe, nesse caso, para trabalhar com o documento inteiro é necessário juntar essas páginas."
      ],
      "metadata": {
        "id": "1vc4PHKBn4YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train_proc_sem_vazio\n",
        "del(df_train_proc_sem_vazio)\n",
        "df_valid = df_valid_proc_sem_vazio\n",
        "del(df_valid_proc_sem_vazio)\n",
        "df_test = df_test_proc_sem_vazio\n",
        "del(df_test_proc_sem_vazio)"
      ],
      "metadata": {
        "id": "dJXQAYicPRcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conjunto de treino\n",
        "df_train['body'] = df_train['body'].astype('str')\n",
        "documents_train = df_train.groupby(['file_name'])['body'].apply(lambda x: ' '.join(x))\n",
        "doc_type = df_train.groupby(['file_name']).agg({'pages': 'last','document_type': 'last'})\n",
        "documents_train = pd.concat([documents_train,doc_type],axis=1)\n",
        "documents_train.reset_index(inplace=True)\n",
        "del(df_train)"
      ],
      "metadata": {
        "id": "wWR5PdYwn4YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conjunto de validacao\n",
        "df_valid['body'] = df_valid['body'].astype('str')\n",
        "documents_valid = df_valid.groupby(['file_name'])['body'].apply(lambda x: ' '.join(x))\n",
        "doc_type = df_valid.groupby(['file_name']).agg({'pages': 'last','document_type': 'last'})\n",
        "documents_valid = pd.concat([documents_valid,doc_type],axis=1)\n",
        "documents_valid.reset_index(inplace=True)\n",
        "del(df_valid)"
      ],
      "metadata": {
        "id": "t3CwEJHjO5YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conjunto de testes\n",
        "df_test['body'] = df_test['body'].astype('str')\n",
        "documents_test = df_test.groupby(['file_name'])['body'].apply(lambda x: ' '.join(x))\n",
        "doc_type = df_test.groupby(['file_name']).agg({'pages': 'last','document_type': 'last'})\n",
        "documents_test = pd.concat([documents_test,doc_type],axis=1)\n",
        "documents_test.reset_index(inplace=True)\n",
        "del(df_test)\n",
        "del(doc_type)"
      ],
      "metadata": {
        "id": "r59e09OHn4YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrando as quantidades"
      ],
      "metadata": {
        "id": "hAZoCu_on4YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantidades(documents_train)"
      ],
      "metadata": {
        "id": "MBlySV81n4YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantidades(documents_valid)"
      ],
      "metadata": {
        "id": "C5KFZ4YnYqve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantidades(documents_test)"
      ],
      "metadata": {
        "id": "I1ZGMf7YYv9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvando documentos com as páginas unidas"
      ],
      "metadata": {
        "id": "J0SaQe-cn4Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_pickle(documents_train,path=path_dados+path_preprocessados,filename='train_processed_concat_pages_sw_lemma.pkl')\n",
        "save_pickle(documents_test,path=path_dados+path_preprocessados,filename='test_processed_concat_pages_sw_lemma.pkl')\n",
        "save_pickle(documents_valid,path=path_dados+path_preprocessados,filename='valid_processed_concat_pages_lemma_sw.pkl')"
      ],
      "metadata": {
        "id": "6Di6CxKkn4Ya"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
